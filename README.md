# ğŸ¤– WatsonX RAG QnA Chatbot

A Retrieval-Augmented Generation (RAG) based document-aware Question & Answering chatbot built using Python with **IBM WatsonX**, **LangChain**, and **Gradio**.  
This application lets you upload a PDF and ask questions about its content. Answers are generated by IBMâ€™s `ibm/granite-3-2-8b-instruct` model, supported by a retrieval pipeline using ChromaDB and `slate-125m-english-rtrvr` embeddings.

<img width="1024" height="1024" alt="Gemini_Generated_Image_pgidl3pgidl3pgid" src="https://github.com/user-attachments/assets/3e157c67-2831-489b-9bba-75f896d4e635" />
Credits - Image Generated using Gemini AI.

---

## ğŸŒŸ Key Features

- **Document Q&A** â€“ Chat directly with your PDF files.  
- **IBM WatsonX Integration** â€“ Uses IBM foundation models for both embedding and generation.  
- **Efficient Retrieval** â€“ Built on **ChromaDB** for fast semantic search and in-memory vector storage.  
- **User-Friendly Interface** â€“ Clean, interactive **Gradio** UI for uploads and questions.

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| **LLM** | IBM Granite-3-2-8B-Instruct |
| **Embeddings** | IBM Slate-125M-English-RTRVR |
| **Frameworks** | LangChain |
| **Vector Database** | ChromaDB |
| **Interface** | Gradio |

---

## ğŸ“¦ Requirements
python 3.11  
gradio==4.44.0   
ibm-watsonx-ai==1.1.2   
langchain==0.2.11   
langchain-community==0.2.10   
langchain-ibm==0.1.11   
chromadb==0.4.24   
pypdf==4.3.1   
pydantic==2.9.1  

## ğŸš€ How to Run Locally
Follow these steps to set up and run the project on your local machine. 
### 1. Clone the Repository

```bash
git clone https://github.com/your-username/watsonx-rag-qnabot.git
cd watsonx-rag-qnabot
```

#### Create a virtual environment
```bash
pip install virtualenv
virtualenv .venv
```

#### Or Simply use
```bash
python -m venv .venv 
```

### 2. Create a Virtual Environment and Install Dependencies

#### Activate it (macOS/Linux)
```bash
source .venv/bin/activate
```

#### Activate it (Windows)
```bash
.venv\Scripts\activate
```

#### Install all required packages
```bash
pip install -r requirements.txt
```

### 3. Set Up Environment Variables
Create a .env file in the project root.
Then open .env and add your IBM Cloud credentials:

```bash
IBM_CLOUD_API_KEY=your_api_key_here
WATSONX_PROJECT_ID=your_project_id
```

### 4. Run the Application

From the project root folder, launch the app:


```bash
python -m src.app
```
Once it starts, open your browser and go to the local URL displayed (usually http://127.0.0.1:7860).

### 5. Upload a PDF for Testing

Use the Gradio interface to upload a PDF file.

Type your question in the input box.

The bot retrieves relevant context from the document and generates an answer using the WatsonX model.

## ğŸ“ Project Structure

```bash
watsonx-rag-qnabot/
â”œâ”€â”€ data/               # Folder for your source PDFs
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py        # Handles document loading, chunking, and embedding
â”‚   â”œâ”€â”€ rag_pipeline.py  # Core RAG logic and model pipeline
â”‚   â”œâ”€â”€ gradio_ui.py     # Gradio interface and app layout
â”‚   â””â”€â”€ app.py           # Main entry point to run the app
â”œâ”€â”€ .env                 # API keys and secrets (ignored by Git)
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation
```

## ğŸ§  How It Works

1. Upload a PDF â€“ The document is parsed and chunked into smaller text segments.

2. Generate Embeddings â€“ Each chunk is converted into vector embeddings using slate-125m-english-rtrvr.

3. Store & Retrieve â€“ Embeddings are stored in ChromaDB for semantic search.

4. Ask a Question â€“ Your question is matched with the most relevant chunks.

5. Answer Generation â€“ The selected context is sent to ibm/granite-3-2-8b-instruct, which produces the final answer.

Sample Query - <img width="1911" height="916" alt="WatsonX Bot" src="https://github.com/user-attachments/assets/024da6c1-60a8-441d-8ed0-6d6b5f51d38e" />


## ğŸ§© Future Improvements

- Support for multi-document queries

- Integration with open-source Hugging Face models (for local inference)

- Optional memory and chat history features

## ğŸ§‘â€ğŸ’» Author

Developed by Anirud R.
Built with â¤ï¸ using IBM WatsonX, LangChain, and Gradio.

## ğŸ“œ License

This project is licensed under the MIT License.
See the LICENSE file for details.
